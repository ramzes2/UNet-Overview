{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet overview.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramzes2/UNet-Overview/blob/master/UNet_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "j6rV9pOs2CPA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **U-Net: Convolutional Networks for Biomedical Image Segmentation**\n",
        "Original article: [https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)\n",
        "\n",
        "Training data was taken from \n",
        "[Konica-Minolta Pathological Image Segmentation Challenge](https://community.topcoder.com/longcontest/?module=ViewProblemStatement&rd=16950&pm=14622)\n"
      ]
    },
    {
      "metadata": {
        "id": "FRN99NaI03Gj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*SNvD04dEFIDwNAqSXLQC_g.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "5nID0ef_FVe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data downloading and extraction"
      ]
    },
    {
      "metadata": {
        "id": "cl9-F6v8HoQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/w0zajni9ny1w8nd/Pathological.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kic7_htnEh7T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf data\n",
        "!mkdir data\n",
        "!unzip Pathological.zip -d data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QC8DrrenH_2s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weroAdjkIT_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo \"Images:\"\n",
        "!ls data/images\n",
        "!echo \"Masks:\"\n",
        "!ls data/truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdnNd5g2FcKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Data overview"
      ]
    },
    {
      "metadata": {
        "id": "FFODJjZhJVHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "TRAIN_IMAGES = 'data/images'\n",
        "TRAIN_MASKS = 'data/truth'\n",
        "\n",
        "file_names = []\n",
        "\n",
        "for file_name in sorted(os.listdir(TRAIN_IMAGES)):\n",
        "  if file_name.endswith('.tif'):\n",
        "    base_name = file_name[:-4]\n",
        "    image_path = f'{TRAIN_IMAGES}/{file_name}'\n",
        "    mask_path = f'{TRAIN_MASKS}/{base_name}_mask.png'\n",
        "    file_names.append((image_path, mask_path))\n",
        "\n",
        "print('Total images:', len(file_names))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQHYbxIXLYg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "ORIG_IMG_WIDTH = 500\n",
        "ORIG_IMG_HEIGHT = 500\n",
        "BORDER = (512 - ORIG_IMG_WIDTH)//2\n",
        "\n",
        "Images = []\n",
        "Masks = []\n",
        "\n",
        "for img_file, mask_file in tqdm(file_names):\n",
        "  image = cv2.imread(img_file)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  mask = cv2.imread(mask_file)\n",
        "  \n",
        "  image = cv2.copyMakeBorder(image, BORDER, BORDER, BORDER, BORDER, cv2.BORDER_REFLECT)\n",
        "  mask = cv2.copyMakeBorder(mask, BORDER, BORDER, BORDER, BORDER, cv2.BORDER_REFLECT)[:, :, 1] == 255\n",
        "  mask = mask.reshape(mask.shape[0], mask.shape[1], -1)\n",
        "  \n",
        "  Images.append(image)\n",
        "  Masks.append(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvkYRliUOJPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "\n",
        "f, ax = plt.subplots(4, 4, figsize=(16, 16))\n",
        "\n",
        "img_idx = 0\n",
        "for row in range(4):\n",
        "  for col in range(2):\n",
        "    ax[row, 2*col].imshow(Images[img_idx])\n",
        "    ax[row, 2*col + 1].imshow(Masks[img_idx].squeeze(), cmap='gray')\n",
        "    img_idx += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dxiKI8SpTV_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "Images = np.array(Images).astype(np.float32)/255\n",
        "Masks = np.array(Masks)\n",
        "\n",
        "trainX, valX, trainY, valY = train_test_split(Images, Masks, test_size=0.3, random_state=42)\n",
        "valX, testX, valY, testY = train_test_split(valX, valY, test_size=0.33, random_state=42)\n",
        "\n",
        "print('Train images:', len(trainX))\n",
        "print('Validation images:', len(valX))\n",
        "print('Test images:', len(testX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-eKcisi0Fdvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## U-net architecture\n",
        "![alt text](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
      ]
    },
    {
      "metadata": {
        "id": "e6G-cCwRY4KY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models, layers, activations\n",
        "\n",
        "def getUnetModel():\n",
        "  def unetBlock(x, filters, skip_conn=None):\n",
        "    if skip_conn is not None:\n",
        "      x = layers.Concatenate() ([skip_conn, x])\n",
        "      \n",
        "    x = layers.Conv2D(filters=filters, kernel_size=3, padding='same') (x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=3, padding='same') (x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "    \n",
        "  inp = layers.Input(shape=(512, 512, 3,))\n",
        "  \n",
        "  filters_cnt = 16\n",
        "  \n",
        "  encoder1 = unetBlock(inp, filters_cnt)\n",
        "  pool1 = layers.MaxPooling2D(2) (encoder1)\n",
        "  \n",
        "  encoder2 = unetBlock(pool1, filters_cnt*2)\n",
        "  pool2 = layers.MaxPooling2D(2) (encoder2)\n",
        "  \n",
        "  encoder3 = unetBlock(pool2, filters_cnt*4)\n",
        "  pool3 = layers.MaxPooling2D(2) (encoder3)\n",
        "  \n",
        "  encoder4 = unetBlock(pool3, filters_cnt*8)\n",
        "  pool4 = layers.MaxPooling2D(2) (encoder4)\n",
        "  \n",
        "  encoder5 = unetBlock(pool4, filters_cnt*16)\n",
        "  \n",
        "  upsampling4 = layers.UpSampling2D(2) (encoder5)\n",
        "  decoder4 = unetBlock(upsampling4, filters_cnt*8, encoder4)\n",
        "  \n",
        "  upsampling3 = layers.UpSampling2D(2) (decoder4)\n",
        "  decoder3 = unetBlock(upsampling3, filters_cnt*4, encoder3)\n",
        "  \n",
        "  upsampling2 = layers.UpSampling2D(2) (decoder3)\n",
        "  decoder2 = unetBlock(upsampling2, filters_cnt*2, encoder2)\n",
        "  \n",
        "  upsampling1 = layers.UpSampling2D(2) (decoder2)\n",
        "  decoder1 = unetBlock(upsampling1, filters_cnt, encoder1)\n",
        "  \n",
        "  output = layers.Conv2D(filters=1, kernel_size=1, padding='same', activation='sigmoid') (decoder1)\n",
        "  \n",
        "  model = models.Model(inputs=inp, outputs=output)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vd_mrUXOf_Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unet = getUnetModel()\n",
        "print(unet.summary() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAJZkkmQh2np",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers, losses\n",
        "\n",
        "unet.compile(optimizer=optimizers.Adam(lr=5e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_hYo3wRV_aS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "batch_size=16\n",
        "epochs=40\n",
        "base_callbacks = [\n",
        "    EarlyStopping(patience=25, verbose=True),\n",
        "    ReduceLROnPlateau(patience=15, verbose=True)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAdEE1i1iH6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unet.fit(x=trainX, y=trainY, batch_size=batch_size, validation_data=[valX, valY], epochs=epochs,\n",
        "        callbacks=[ModelCheckpoint('model_unet.h5', save_best_only=True, save_weights_only=True, verbose=True)] + base_callbacks) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCjEX1mbXz0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualizePrediction(X, y_true, y_pred, samples, thr=0.5):\n",
        "  f, ax = plt.subplots(samples, 4, figsize=(4*samples, 16))\n",
        "  \n",
        "  for i in range(samples):\n",
        "    gt = np.squeeze(y_true[i]).astype(np.bool)\n",
        "    mask = np.squeeze(y_pred[i]) >= thr\n",
        "    \n",
        "    vis = np.zeros((512, 512, 3), dtype=np.float32)\n",
        "    vis[:, :, 1] = np.logical_and(mask, gt)\n",
        "    vis[:, :, 0] = np.logical_and(gt, np.logical_not(mask))\n",
        "    vis[:, :, 2] = np.logical_and(np.logical_not(gt), mask)\n",
        "    \n",
        "    ax[i, 0].imshow(X[i], vmin=0, vmax=1)\n",
        "    ax[i, 1].imshow(np.squeeze(y_true[i]), cmap='gray', vmin=0, vmax=1)\n",
        "    ax[i, 2].imshow(np.squeeze(y_pred[i]), cmap='gray', vmin=0, vmax=1)\n",
        "    ax[i, 3].imshow(vis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TS99KyumZIyR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unet.load_weights('model_unet.h5')\n",
        "p = unet.predict(valX, verbose=True)\n",
        "\n",
        "visualizePrediction(valX, valY, p, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8929ajRoTRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calc_accuracy(y_true, y_pred):\n",
        "  y_true = y_true[:, BORDER:-BORDER, BORDER:-BORDER]\n",
        "  y_pred = y_pred[:, BORDER:-BORDER, BORDER:-BORDER]\n",
        "  y_pred = np.round(y_pred)\n",
        "  \n",
        "  return accuracy_score(y_true.astype(np.uint32).flatten(), y_pred.astype(np.uint32).flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fyQB5ZpUot7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unet_acc = (calc_accuracy(trainY, unet.predict(trainX)), calc_accuracy(valY, unet.predict(valX)), calc_accuracy(testY, unet.predict(testX)))\n",
        "\n",
        "\n",
        "print('Train accuracy:', unet_acc[0])\n",
        "print('Validation accuracy:',  unet_acc[1])\n",
        "print('Test accuracy:',  unet_acc[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zoTT9IxA6XUb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## How we can improve the accuracy?\n",
        "\n",
        "1.   Augmentations\n",
        "> * [albumentations](https://github.com/albu/albumentations)\n",
        "> * [imgaug](https://github.com/aleju/imgaug)\n",
        "2.   Batch normalization\n",
        "3.   Dropout\n",
        "4.   Custom loss-function\n",
        "5.   Test Time Augmentation\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ODsCmjbfM-bT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Custom loss-function"
      ]
    },
    {
      "metadata": {
        "id": "dyq7YR7oM9iJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "  \n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "  return losses.binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kacmYK_UNjlJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unet2 = getUnetModel()\n",
        "unet2.compile(optimizer=optimizers.Adam(lr=5e-4),\n",
        "              loss=bce_dice_loss,\n",
        "              metrics=['accuracy', 'binary_crossentropy'])\n",
        "unet2.load_weights('model_unet.h5')\n",
        "\n",
        "unet2.fit(x=trainX, y=trainY, batch_size=batch_size, validation_data=[valX, valY], epochs=20,\n",
        "        callbacks=[ModelCheckpoint('model_unet2.h5', save_best_only=True, save_weights_only=True, verbose=True)] + base_callbacks) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ingOt8ClP0L7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unet2.load_weights('model_unet2.h5')\n",
        "\n",
        "unet2_acc = (calc_accuracy(trainY, unet2.predict(trainX)), calc_accuracy(valY, unet2.predict(valX)), calc_accuracy(testY, unet2.predict(testX)))\n",
        "\n",
        "print('Train accuracy:', unet2_acc[0])\n",
        "print('Validation accuracy:',  unet2_acc[1])\n",
        "print('Test accuracy:',  unet2_acc[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2e1O1zRqKih",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Test Time Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "Q655ugwRqNbV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tta_transform(X, hor_flip, ver_flip):\n",
        "  res = []\n",
        "  for i in range(len(X)):\n",
        "    img = X[i]\n",
        "    if hor_flip:\n",
        "      img = np.fliplr(img)\n",
        "    if ver_flip:\n",
        "      img = np.flipud(img)\n",
        "    res.append(img)\n",
        "    \n",
        "  return np.array(res)\n",
        "\n",
        "def tta_restore(X, hor_flip, ver_flip):\n",
        "  res = []\n",
        "  for i in range(len(X)):\n",
        "    img = X[i]\n",
        "    if ver_flip:\n",
        "      img = np.flipud(img)\n",
        "    if hor_flip:\n",
        "      img = np.fliplr(img)\n",
        "    \n",
        "    res.append(img)\n",
        "    \n",
        "  return np.array(res)\n",
        "\n",
        "def predict_tta(model, X):\n",
        "  res = np.zeros((X.shape[0], X.shape[1], X.shape[2], 1), dtype=np.float32)\n",
        "  \n",
        "  for hor_flip in range(2):\n",
        "    for ver_flip in range(2):\n",
        "        X2 = tta_transform(X, hor_flip, ver_flip)\n",
        "        p2 = model.predict(X2)\n",
        "        p = tta_restore(p2, hor_flip, ver_flip)\n",
        "        \n",
        "        res += p\n",
        "  \n",
        "  return res/4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNCfzpCSsNEQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_predict_tta = predict_tta(unet, trainX)\n",
        "val_predict_tta = predict_tta(unet, valX)\n",
        "test_predict_tta = predict_tta(unet, testX)\n",
        "\n",
        "print('Unet binary_crossentropy loss:')\n",
        "unet_tta_acc = (calc_accuracy(trainY, train_predict_tta), calc_accuracy(valY, val_predict_tta), calc_accuracy(testY, test_predict_tta))\n",
        "\n",
        "print('Train accuracy:', unet_tta_acc[0])\n",
        "print('Validation accuracy:',  unet_tta_acc[1])\n",
        "print('Test accuracy:',  unet_tta_acc[2])\n",
        "\n",
        "train_predict_tta2 = predict_tta(unet2, trainX)\n",
        "val_predict_tta2 = predict_tta(unet2, valX)\n",
        "test_predict_tta2 = predict_tta(unet2, testX)\n",
        "\n",
        "print('')\n",
        "\n",
        "print('Unet BCE+Dice loss:')\n",
        "unet2_tta_acc = (calc_accuracy(trainY, train_predict_tta2), calc_accuracy(valY, val_predict_tta2), calc_accuracy(testY, test_predict_tta2))\n",
        "\n",
        "print('Train accuracy:', unet2_tta_acc[0])\n",
        "print('Validation accuracy:',  unet2_tta_acc[1])\n",
        "print('Test accuracy:',  unet2_tta_acc[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5JvKXouHbyLt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Final results"
      ]
    },
    {
      "metadata": {
        "id": "qyfxjiHWY8CG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "acc = np.array([unet_acc, unet2_acc,unet_tta_acc, unet2_tta_acc])\n",
        "\n",
        "scores = pd.DataFrame({'method:': ['U-Net BCE', 'U-Net BCE+Dice', 'U-Net BCE TTA', 'U-Net BCE+Dice TTA'],\n",
        "                      'train acc': acc[:, 0], 'val acc': acc[:, 1], 'test acc': acc[:, 2]})\n",
        "\n",
        "scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vOWcP1nbPTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualizePrediction(valX, valY, val_predict_tta2, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}